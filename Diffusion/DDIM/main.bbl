\begin{thebibliography}{41}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi: #1}\else
  \providecommand{\doi}{doi: \begingroup \urlstyle{rm}\Url}\fi

\bibitem[Arjovsky et~al.(2017)Arjovsky, Chintala, and
  Bottou]{arjovsky2017wasserstein}
Martin Arjovsky, Soumith Chintala, and L{\'e}on Bottou.
\newblock Wasserstein {GAN}.
\newblock \emph{arXiv preprint arXiv:1701.07875}, January 2017.

\bibitem[Bau et~al.(2019)Bau, Zhu, Wulff, Peebles, Strobelt, Zhou, and
  Torralba]{bau2019seeing}
David Bau, Jun-Yan Zhu, Jonas Wulff, William Peebles, Hendrik Strobelt, Bolei
  Zhou, and Antonio Torralba.
\newblock Seeing what a gan cannot generate.
\newblock In \emph{Proceedings of the IEEE International Conference on Computer
  Vision}, pp.\  4502--4511, 2019.

\bibitem[Bengio et~al.(2014)Bengio, Laufer, Alain, and
  Yosinski]{bengio2014deep}
Yoshua Bengio, Eric Laufer, Guillaume Alain, and Jason Yosinski.
\newblock Deep generative stochastic networks trainable by backprop.
\newblock In \emph{International Conference on Machine Learning}, pp.\
  226--234, January 2014.

\bibitem[Bishop(2006)]{bishop2006pattern}
Christopher~M Bishop.
\newblock \emph{Pattern recognition and machine learning}.
\newblock springer, 2006.

\bibitem[Brock et~al.(2018)Brock, Donahue, and Simonyan]{brock2018large}
Andrew Brock, Jeff Donahue, and Karen Simonyan.
\newblock Large scale {GAN} training for high fidelity natural image synthesis.
\newblock \emph{arXiv preprint arXiv:1809.11096}, September 2018.

\bibitem[Butcher \& Goodwin(2008)Butcher and Goodwin]{butcher2008numerical}
John~Charles Butcher and Nicolette Goodwin.
\newblock \emph{Numerical methods for ordinary differential equations},
  volume~2.
\newblock Wiley Online Library, 2008.

\bibitem[Chen et~al.(2020)Chen, Zhang, Zen, Weiss, Norouzi, and
  Chan]{chen2020wavegrad}
Nanxin Chen, Yu~Zhang, Heiga Zen, Ron~J Weiss, Mohammad Norouzi, and William
  Chan.
\newblock {WaveGrad}: Estimating gradients for waveform generation.
\newblock \emph{arXiv preprint arXiv:2009.00713}, September 2020.

\bibitem[Chen et~al.(2018)Chen, Rubanova, Bettencourt, and
  Duvenaud]{chen2018neural}
Ricky T~Q Chen, Yulia Rubanova, Jesse Bettencourt, and David Duvenaud.
\newblock Neural ordinary differential equations.
\newblock \emph{arXiv preprint arXiv:1806.07366}, June 2018.

\bibitem[Dinh et~al.(2016)Dinh, Sohl-Dickstein, and Bengio]{dinh2016density}
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
\newblock Density estimation using real {NVP}.
\newblock \emph{arXiv preprint arXiv:1605.08803}, May 2016.

\bibitem[Goodfellow et~al.(2014)Goodfellow, Pouget-Abadie, Mirza, Xu,
  Warde-Farley, Ozair, Courville, and Bengio]{goodfellow2014generative}
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
  Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial nets.
\newblock In \emph{Advances in neural information processing systems}, pp.\
  2672--2680, 2014.

\bibitem[Goyal et~al.(2017)Goyal, Ke, Ganguli, and
  Bengio]{goyal2017variational}
Anirudh Goyal, Nan~Rosemary Ke, Surya Ganguli, and Yoshua Bengio.
\newblock Variational walkback: Learning a transition operator as a stochastic
  recurrent net.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  4392--4402, 2017.

\bibitem[Grathwohl et~al.(2018)Grathwohl, Chen, Bettencourt, Sutskever, and
  Duvenaud]{grathwohl2018ffjord}
Will Grathwohl, Ricky T~Q Chen, Jesse Bettencourt, Ilya Sutskever, and David
  Duvenaud.
\newblock {FFJORD}: Free-form continuous dynamics for scalable reversible
  generative models.
\newblock \emph{arXiv preprint arXiv:1810.01367}, October 2018.

\bibitem[Gulrajani et~al.(2017)Gulrajani, Ahmed, Arjovsky, Dumoulin, and
  Courville]{gulrajani2017improved}
Ishaan Gulrajani, Faruk Ahmed, Martin Arjovsky, Vincent Dumoulin, and Aaron~C
  Courville.
\newblock Improved training of wasserstein gans.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  5769--5779, 2017.

\bibitem[Heusel et~al.(2017)Heusel, Ramsauer, Unterthiner, Nessler, and
  Hochreiter]{heusel2017gans}
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp
  Hochreiter.
\newblock {GANs} trained by a two {Time-Scale} update rule converge to a local
  nash equilibrium.
\newblock \emph{arXiv preprint arXiv:1706.08500}, June 2017.

\bibitem[Ho et~al.(2020)Ho, Jain, and Abbeel]{ho2020denoising}
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
\newblock Denoising diffusion probabilistic models.
\newblock \emph{arXiv preprint arXiv:2006.11239}, June 2020.

\bibitem[Hyv{\"a}rinen(2005)]{h2005estimation}
Aapo Hyv{\"a}rinen.
\newblock Estimation of {Non-Normalized} statistical models by score matching.
\newblock \emph{Journal of Machine Learning Researc h}, 6:\penalty0 695--709,
  2005.

\bibitem[Jolicoeur-Martineau et~al.(2020)Jolicoeur-Martineau,
  Pich{\'e}-Taillefer, des Combes, and
  Mitliagkas]{Jolicoeur-Martineau2020adversarial}
Alexia Jolicoeur-Martineau, R{\'e}mi Pich{\'e}-Taillefer, R{\'e}mi~Tachet des
  Combes, and Ioannis Mitliagkas.
\newblock Adversarial score matching and improved sampling for image
  generation.
\newblock September 2020.

\bibitem[Jordan et~al.(1998)Jordan, Kinderlehrer, and
  Otto]{jordan1998variational}
Richard Jordan, David Kinderlehrer, and Felix Otto.
\newblock The variational formulation of the fokker--planck equation.
\newblock \emph{SIAM journal on mathematical analysis}, 29\penalty0
  (1):\penalty0 1--17, 1998.

\bibitem[Karras et~al.(2018)Karras, Laine, and Aila]{karras2018a}
Tero Karras, Samuli Laine, and Timo Aila.
\newblock A {Style-Based} generator architecture for generative adversarial
  networks.
\newblock \emph{arXiv preprint arXiv:1812.04948}, December 2018.

\bibitem[Karras et~al.(2020)Karras, Laine, Aittala, Hellsten, Lehtinen, and
  Aila]{karras2020analyzing}
Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and
  Timo Aila.
\newblock Analyzing and improving the image quality of stylegan.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, pp.\  8110--8119, 2020.

\bibitem[Kingma \& Welling(2013)Kingma and Welling]{kingma2013auto}
Diederik~P Kingma and Max Welling.
\newblock {Auto-Encoding} variational bayes.
\newblock \emph{arXiv preprint arXiv:1312.6114v10}, December 2013.

\bibitem[Levy et~al.(2017)Levy, Hoffman, and
  Sohl-Dickstein]{levy2017generalizing}
Daniel Levy, Matthew~D Hoffman, and Jascha Sohl-Dickstein.
\newblock Generalizing hamiltonian monte carlo with neural networks.
\newblock \emph{arXiv preprint arXiv:1711.09268}, 2017.

\bibitem[Mohamed \& Lakshminarayanan(2016)Mohamed and
  Lakshminarayanan]{mohamed2016learning}
Shakir Mohamed and Balaji Lakshminarayanan.
\newblock Learning in implicit generative models.
\newblock \emph{arXiv preprint arXiv:1610.03483}, October 2016.

\bibitem[Neal et~al.(2011)]{neal2011mcmc}
Radford~M Neal et~al.
\newblock Mcmc using hamiltonian dynamics.
\newblock \emph{Handbook of markov chain monte carlo}, 2\penalty0
  (11):\penalty0 2, 2011.

\bibitem[Queiruga et~al.(2020)Queiruga, Erichson, Taylor, and
  Mahoney]{queiruga2020continuous}
Alejandro~F Queiruga, N~Benjamin Erichson, Dane Taylor, and Michael~W Mahoney.
\newblock Continuous-in-depth neural networks.
\newblock \emph{arXiv preprint arXiv:2008.02389}, 2020.

\bibitem[Raphan \& Simoncelli(2011)Raphan and Simoncelli]{raphan2011least}
Martin Raphan and Eero~P Simoncelli.
\newblock Least squares estimation without priors or supervision.
\newblock \emph{Neural computation}, 23\penalty0 (2):\penalty0 374--420,
  February 2011.
\newblock ISSN 0899-7667, 1530-888X.

\bibitem[Rezende \& Mohamed(2015)Rezende and Mohamed]{rezende2015variational}
Danilo~Jimenez Rezende and Shakir Mohamed.
\newblock Variational inference with normalizing flows.
\newblock \emph{arXiv preprint arXiv:1505.05770}, May 2015.

\bibitem[Rezende et~al.(2014)Rezende, Mohamed, and
  Wierstra]{rezende2014stochastic}
Danilo~Jimenez Rezende, Shakir Mohamed, and Daan Wierstra.
\newblock Stochastic backpropagation and approximate inference in deep
  generative models.
\newblock \emph{arXiv preprint arXiv:1401.4082}, 2014.

\bibitem[Ronneberger et~al.(2015)Ronneberger, Fischer, and
  Brox]{ronneberger2015u}
Olaf Ronneberger, Philipp Fischer, and Thomas Brox.
\newblock U-net: Convolutional networks for biomedical image segmentation.
\newblock In \emph{International Conference on Medical image computing and
  computer-assisted intervention}, pp.\  234--241. Springer, 2015.

\bibitem[Salimans et~al.(2014)Salimans, Kingma, and
  Welling]{salimans2014markov}
Tim Salimans, Diederik~P Kingma, and Max Welling.
\newblock Markov chain monte carlo and variational inference: Bridging the gap.
\newblock \emph{arXiv preprint arXiv:1410.6460}, October 2014.

\bibitem[Shoemake(1985)]{shoemake1985animating}
Ken Shoemake.
\newblock Animating rotation with quaternion curves.
\newblock In \emph{Proceedings of the 12th annual conference on Computer
  graphics and interactive techniques}, pp.\  245--254, 1985.

\bibitem[Sohl-Dickstein et~al.(2015)Sohl-Dickstein, Weiss, Maheswaranathan, and
  Ganguli]{sohl-dickstein2015deep}
Jascha Sohl-Dickstein, Eric~A Weiss, Niru Maheswaranathan, and Surya Ganguli.
\newblock Deep unsupervised learning using nonequilibrium thermodynamics.
\newblock \emph{arXiv preprint arXiv:1503.03585}, March 2015.

\bibitem[Song et~al.(2017)Song, Zhao, and Ermon]{song2017a}
Jiaming Song, Shengjia Zhao, and Stefano Ermon.
\newblock A-nice-mc: Adversarial training for mcmc.
\newblock \emph{arXiv preprint arXiv:1706.07561}, June 2017.

\bibitem[Song \& Ermon(2019)Song and Ermon]{song2019generative}
Yang Song and Stefano Ermon.
\newblock Generative modeling by estimating gradients of the data distribution.
\newblock \emph{arXiv preprint arXiv:1907.05600}, July 2019.

\bibitem[Song \& Ermon(2020)Song and Ermon]{song2020improved}
Yang Song and Stefano Ermon.
\newblock Improved techniques for training {Score-Based} generative models.
\newblock \emph{arXiv preprint arXiv:2006.09011}, June 2020.

\bibitem[Song et~al.(2020)Song, Sohl-Dickstein, Kingma, Kumar, Ermon, and
  Poole]{song2020score}
Yang Song, Jascha Sohl-Dickstein, Diederik~P Kingma, Abhishek Kumar, Stefano
  Ermon, and Ben Poole.
\newblock Score-based generative modeling through stochastic differential
  equations.
\newblock \emph{arXiv preprint arXiv:2011.13456}, 2020.

\bibitem[van~den Oord et~al.(2016{\natexlab{a}})van~den Oord, Dieleman, Zen,
  Simonyan, Vinyals, Graves, Kalchbrenner, Senior, and
  Kavukcuoglu]{oord2016wavenet}
Aaron van~den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
  Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
\newblock {WaveNet}: A generative model for raw audio.
\newblock \emph{arXiv preprint arXiv:1609.03499}, September 2016{\natexlab{a}}.

\bibitem[van~den Oord et~al.(2016{\natexlab{b}})van~den Oord, Kalchbrenner, and
  Kavukcuoglu]{oord2016pixel}
Aaron van~den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
\newblock Pixel recurrent neural networks.
\newblock \emph{arXiv preprint arXiv:1601.06759}, January 2016{\natexlab{b}}.

\bibitem[Vincent(2011)]{vincent2011connection}
Pascal Vincent.
\newblock A connection between score matching and denoising autoencoders.
\newblock \emph{Neural computation}, 23\penalty0 (7):\penalty0 1661--1674,
  2011.

\bibitem[Zagoruyko \& Komodakis(2016)Zagoruyko and
  Komodakis]{zagoruyko2016wide}
Sergey Zagoruyko and Nikos Komodakis.
\newblock Wide residual networks.
\newblock \emph{arXiv preprint arXiv:1605.07146}, May 2016.

\bibitem[Zhao et~al.(2018)Zhao, Ren, Yuan, Song, Goodman, and
  Ermon]{zhao2018bias}
Shengjia Zhao, Hongyu Ren, Arianna Yuan, Jiaming Song, Noah Goodman, and
  Stefano Ermon.
\newblock Bias and generalization in deep generative models: An empirical
  study.
\newblock In \emph{Advances in Neural Information Processing Systems}, pp.\
  10792--10801, 2018.

\end{thebibliography}
