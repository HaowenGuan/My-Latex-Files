
\documentclass{article} %
\usepackage{iclr2021_conference,times}
\usepackage{subcaption}
\usepackage{graphicx}
\input{math_commands.tex}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{multirow}
\usepackage{array}
\usepackage{caption}
\usepackage{hyperref}
\hypersetup{colorlinks = true, linkcolor = brown,
            urlcolor  = gray,
            citecolor = brown,
            anchorcolor = brown}
\usepackage{xcolor}
\usepackage{colortbl}
\usepackage{tipa}
\allowdisplaybreaks
\title{Denoising Diffusion Implicit Models}

\iclrfinalcopy

\author{Jiaming Song, Chenlin Meng \& Stefano Ermon\\
Stanford University\\
\texttt{\{tsong,chenlin,ermon\}@cs.stanford.edu}}


\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\begin{document}


\maketitle

\begin{abstract}
Denoising diffusion probabilistic models (DDPMs) have achieved high quality image generation without adversarial training, yet they require simulating a Markov chain for many steps in order to produce a sample. To accelerate sampling, we present denoising diffusion implicit models (DDIMs), a more efficient class of iterative implicit probabilistic models with the same training procedure as DDPMs. In DDPMs, the generative process is defined as the reverse of a particular Markovian diffusion process. We generalize DDPMs via a class of non-Markovian diffusion processes that lead to the same training objective. These non-Markovian processes can correspond to generative processes that are deterministic, giving rise to implicit models that produce high quality samples much faster. We empirically demonstrate that DDIMs can produce high quality samples $10 \times$ to $50 \times$ faster in terms of wall-clock time compared to DDPMs, allow us to trade off computation for sample quality, perform semantically meaningful image interpolation directly in the latent space, and reconstruct observations with very low error. 
\end{abstract}

\input{sections/1_introduction}
\input{sections/2_background}
\input{sections/3_method}
\input{sections/4_experiments}
\input{sections/5_related}
\input{sections/6_discussion}

\section*{Acknowledgements}
The authors would like to thank Yang Song and Shengjia Zhao for helpful discussions over the ideas, Kuno Kim for reviewing an earlier draft of the paper, and Sharvil Nanavati and Sophie Liu for identifying typos. This research was supported by NSF (\#1651565, \#1522054, \#1733686), ONR (N00014-19-1-2145), AFOSR (FA9550-19-1-0024), and Amazon AWS.


\bibliography{iclr2021_conference}
\bibliographystyle{iclr2021_conference}

\input{sections/9_appendix}

\end{document}
